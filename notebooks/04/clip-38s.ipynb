{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "## Linear Regression"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "### Added snippet used as a reference for all models"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "This model is based on the TuringTutorial example [LinearRegression](https://github.com/TuringLang/TuringTutorials/blob/csp/linear/LinearRegression.ipynb) by Cameron Pfiffer."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Turing is powerful when applied to complex hierarchical models, but it can also be put to task at common statistical procedures, like linear regression. This tutorial covers how to implement a linear regression model in Turing."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "We begin by importing all the necessary libraries."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using StatisticalRethinking, CmdStan, GLM\n",
    "#gr(size=(600,600))\n",
    "\n",
    "ProjDir = rel_path(\"..\", \"scripts\", \"00\")\n",
    "cd(ProjDir)"
   ],
   "metadata": {},
   "execution_count": 1
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Import the dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "howell1 = CSV.read(rel_path(\"..\", \"data\", \"Howell1.csv\"), delim=';')\n",
    "df = convert(DataFrame, howell1);"
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Use only adults"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "352×4 DataFrame\n│ Row │ height  │ weight  │ age     │ male  │\n│     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n├─────┼─────────┼─────────┼─────────┼───────┤\n│ 1   │ 151.765 │ 47.8256 │ 63.0    │ 1     │\n│ 2   │ 139.7   │ 36.4858 │ 63.0    │ 0     │\n│ 3   │ 136.525 │ 31.8648 │ 65.0    │ 0     │\n│ 4   │ 156.845 │ 53.0419 │ 41.0    │ 1     │\n│ 5   │ 145.415 │ 41.2769 │ 51.0    │ 0     │\n│ 6   │ 163.83  │ 62.9926 │ 35.0    │ 1     │\n│ 7   │ 149.225 │ 38.2435 │ 32.0    │ 0     │\n⋮\n│ 345 │ 146.05  │ 39.4058 │ 37.4    │ 0     │\n│ 346 │ 156.21  │ 41.0501 │ 53.0    │ 1     │\n│ 347 │ 152.4   │ 40.8233 │ 49.0    │ 0     │\n│ 348 │ 162.56  │ 47.0318 │ 27.0    │ 0     │\n│ 349 │ 142.875 │ 34.2462 │ 31.0    │ 0     │\n│ 350 │ 162.56  │ 52.1631 │ 31.0    │ 1     │\n│ 351 │ 156.21  │ 54.0625 │ 21.0    │ 0     │\n│ 352 │ 158.75  │ 52.5316 │ 68.0    │ 1     │",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>height</th><th>weight</th><th>age</th><th>male</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>352 rows × 4 columns</p><tr><th>1</th><td>151.765</td><td>47.8256</td><td>63.0</td><td>1</td></tr><tr><th>2</th><td>139.7</td><td>36.4858</td><td>63.0</td><td>0</td></tr><tr><th>3</th><td>136.525</td><td>31.8648</td><td>65.0</td><td>0</td></tr><tr><th>4</th><td>156.845</td><td>53.0419</td><td>41.0</td><td>1</td></tr><tr><th>5</th><td>145.415</td><td>41.2769</td><td>51.0</td><td>0</td></tr><tr><th>6</th><td>163.83</td><td>62.9926</td><td>35.0</td><td>1</td></tr><tr><th>7</th><td>149.225</td><td>38.2435</td><td>32.0</td><td>0</td></tr><tr><th>8</th><td>168.91</td><td>55.48</td><td>27.0</td><td>1</td></tr><tr><th>9</th><td>147.955</td><td>34.8699</td><td>19.0</td><td>0</td></tr><tr><th>10</th><td>165.1</td><td>54.4877</td><td>54.0</td><td>1</td></tr><tr><th>11</th><td>154.305</td><td>49.8951</td><td>47.0</td><td>0</td></tr><tr><th>12</th><td>151.13</td><td>41.2202</td><td>66.0</td><td>1</td></tr><tr><th>13</th><td>144.78</td><td>36.0322</td><td>73.0</td><td>0</td></tr><tr><th>14</th><td>149.9</td><td>47.7</td><td>20.0</td><td>0</td></tr><tr><th>15</th><td>150.495</td><td>33.8493</td><td>65.3</td><td>0</td></tr><tr><th>16</th><td>163.195</td><td>48.5627</td><td>36.0</td><td>1</td></tr><tr><th>17</th><td>157.48</td><td>42.3258</td><td>44.0</td><td>1</td></tr><tr><th>18</th><td>143.942</td><td>38.3569</td><td>31.0</td><td>0</td></tr><tr><th>19</th><td>161.29</td><td>48.9879</td><td>39.0</td><td>1</td></tr><tr><th>20</th><td>156.21</td><td>42.7227</td><td>29.0</td><td>0</td></tr><tr><th>21</th><td>146.4</td><td>35.4936</td><td>56.0</td><td>1</td></tr><tr><th>22</th><td>148.59</td><td>37.9033</td><td>45.0</td><td>0</td></tr><tr><th>23</th><td>147.32</td><td>35.4652</td><td>19.0</td><td>0</td></tr><tr><th>24</th><td>147.955</td><td>40.313</td><td>29.0</td><td>1</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "cell_type": "code",
   "source": [
    "data = filter(row -> row[:age] >= 18, df)"
   ],
   "metadata": {},
   "execution_count": 3
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Show the first six rows of the dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6×4 DataFrame\n│ Row │ height  │ weight  │ age     │ male  │\n│     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n├─────┼─────────┼─────────┼─────────┼───────┤\n│ 1   │ 151.765 │ 47.8256 │ 63.0    │ 1     │\n│ 2   │ 139.7   │ 36.4858 │ 63.0    │ 0     │\n│ 3   │ 136.525 │ 31.8648 │ 65.0    │ 0     │\n│ 4   │ 156.845 │ 53.0419 │ 41.0    │ 1     │\n│ 5   │ 145.415 │ 41.2769 │ 51.0    │ 0     │\n│ 6   │ 163.83  │ 62.9926 │ 35.0    │ 1     │",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>height</th><th>weight</th><th>age</th><th>male</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>6 rows × 4 columns</p><tr><th>1</th><td>151.765</td><td>47.8256</td><td>63.0</td><td>1</td></tr><tr><th>2</th><td>139.7</td><td>36.4858</td><td>63.0</td><td>0</td></tr><tr><th>3</th><td>136.525</td><td>31.8648</td><td>65.0</td><td>0</td></tr><tr><th>4</th><td>156.845</td><td>53.0419</td><td>41.0</td><td>1</td></tr><tr><th>5</th><td>145.415</td><td>41.2769</td><td>51.0</td><td>0</td></tr><tr><th>6</th><td>163.83</td><td>62.9926</td><td>35.0</td><td>1</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "cell_type": "code",
   "source": [
    "first(data, 6)"
   ],
   "metadata": {},
   "execution_count": 4
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "The next step is to get our data ready for testing. We'll split the mtcars dataset into two subsets, one for training our model and one for evaluating our model. Then, we separate the labels we want to learn (MPG, in this case) and standardize the datasets by subtracting each column's means and dividing by the standard deviation of that column."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "The resulting data is not very familiar looking, but this standardization process helps the sampler converge far easier. We also create a function called unstandardize, which returns the standardized values to their original form. We will use this function later on when we make predictions."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Split our dataset 70%/30% into training/test sets."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n = size(data, 1)\n",
    "test_ind = sample(1:n, Int(floor(0.3*n)), replace=false);\n",
    "train_ind = [(i) for i=1:n if !(i in test_ind)];\n",
    "test = data[test_ind, :];\n",
    "train = data[train_ind, :];"
   ],
   "metadata": {},
   "execution_count": 5
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Save dataframe versions of our dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "105×4 DataFrame\n│ Row │ height  │ weight  │ age     │ male  │\n│     │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n├─────┼─────────┼─────────┼─────────┼───────┤\n│ 1   │ 159.385 │ 47.2019 │ 28.0    │ 1     │\n│ 2   │ 150.165 │ 41.9573 │ 22.0    │ 0     │\n│ 3   │ 151.765 │ 42.524  │ 83.4    │ 1     │\n│ 4   │ 147.955 │ 39.3775 │ 30.0    │ 0     │\n│ 5   │ 147.32  │ 40.8516 │ 64.0    │ 0     │\n│ 6   │ 146.05  │ 42.8077 │ 23.0    │ 0     │\n│ 7   │ 146.05  │ 34.1895 │ 23.0    │ 0     │\n⋮\n│ 98  │ 162.56  │ 56.0186 │ 42.0    │ 1     │\n│ 99  │ 149.86  │ 38.6971 │ 58.0    │ 0     │\n│ 100 │ 160.02  │ 49.2714 │ 23.0    │ 1     │\n│ 101 │ 154.94  │ 45.4442 │ 31.0    │ 1     │\n│ 102 │ 160.655 │ 54.0908 │ 26.0    │ 1     │\n│ 103 │ 146.05  │ 39.4058 │ 37.4    │ 0     │\n│ 104 │ 167.005 │ 56.7557 │ 50.0    │ 1     │\n│ 105 │ 160.02  │ 59.5623 │ 24.0    │ 1     │",
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>height</th><th>weight</th><th>age</th><th>male</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Int64</th></tr></thead><tbody><p>105 rows × 4 columns</p><tr><th>1</th><td>159.385</td><td>47.2019</td><td>28.0</td><td>1</td></tr><tr><th>2</th><td>150.165</td><td>41.9573</td><td>22.0</td><td>0</td></tr><tr><th>3</th><td>151.765</td><td>42.524</td><td>83.4</td><td>1</td></tr><tr><th>4</th><td>147.955</td><td>39.3775</td><td>30.0</td><td>0</td></tr><tr><th>5</th><td>147.32</td><td>40.8516</td><td>64.0</td><td>0</td></tr><tr><th>6</th><td>146.05</td><td>42.8077</td><td>23.0</td><td>0</td></tr><tr><th>7</th><td>146.05</td><td>34.1895</td><td>23.0</td><td>0</td></tr><tr><th>8</th><td>142.875</td><td>35.607</td><td>42.0</td><td>0</td></tr><tr><th>9</th><td>165.1</td><td>51.1992</td><td>49.0</td><td>1</td></tr><tr><th>10</th><td>147.32</td><td>36.8827</td><td>22.0</td><td>0</td></tr><tr><th>11</th><td>153.035</td><td>39.5476</td><td>33.0</td><td>0</td></tr><tr><th>12</th><td>165.735</td><td>48.3359</td><td>30.0</td><td>1</td></tr><tr><th>13</th><td>164.465</td><td>45.8978</td><td>50.0</td><td>1</td></tr><tr><th>14</th><td>170.18</td><td>48.5627</td><td>41.0</td><td>1</td></tr><tr><th>15</th><td>168.91</td><td>58.8252</td><td>41.0</td><td>1</td></tr><tr><th>16</th><td>164.465</td><td>52.1631</td><td>71.0</td><td>1</td></tr><tr><th>17</th><td>163.195</td><td>48.5627</td><td>36.0</td><td>1</td></tr><tr><th>18</th><td>160.655</td><td>39.7743</td><td>65.0</td><td>1</td></tr><tr><th>19</th><td>152.4</td><td>43.8567</td><td>33.0</td><td>1</td></tr><tr><th>20</th><td>163.195</td><td>51.0291</td><td>39.0</td><td>1</td></tr><tr><th>21</th><td>157.48</td><td>50.8023</td><td>19.0</td><td>0</td></tr><tr><th>22</th><td>154.94</td><td>48.1375</td><td>26.0</td><td>0</td></tr><tr><th>23</th><td>146.05</td><td>37.5064</td><td>24.0</td><td>0</td></tr><tr><th>24</th><td>161.925</td><td>47.287</td><td>60.0</td><td>1</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "cell_type": "code",
   "source": [
    "train_cut = DataFrame(train)\n",
    "test_cut = DataFrame(test)"
   ],
   "metadata": {},
   "execution_count": 6
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Create our labels. These are the values we are trying to predict."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "105-element Array{Float64,1}:\n 159.385 \n 150.1648\n 151.765 \n 147.955 \n 147.32  \n 146.05  \n 146.05  \n 142.875 \n 165.1   \n 147.32  \n   ⋮     \n 156.21  \n 162.56  \n 149.86  \n 160.02  \n 154.94  \n 160.655 \n 146.05  \n 167.005 \n 160.02  "
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "cell_type": "code",
   "source": [
    "train_label = train[:, :height]\n",
    "test_label = test[:, :height]"
   ],
   "metadata": {},
   "execution_count": 7
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Get the list of columns to keep."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1-element Array{Symbol,1}:\n :weight"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "cell_type": "code",
   "source": [
    "remove_names = filter(x->!in(x, [:height, :age, :male]), names(data))"
   ],
   "metadata": {},
   "execution_count": 8
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Filter the test and train sets."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train = Matrix(train[:, remove_names]);\n",
    "test = Matrix(test[:, remove_names]);"
   ],
   "metadata": {},
   "execution_count": 9
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "A handy helper function to rescale our dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "standardize (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "cell_type": "code",
   "source": [
    "function standardize(x)\n",
    "    return (x .- mean(x, dims=1)) ./ std(x, dims=1), x\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 10
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Another helper function to unstandardize our datasets."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "unstandardize (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "cell_type": "code",
   "source": [
    "function unstandardize(x, orig)\n",
    "    return x .* std(orig, dims=1) .+ mean(orig, dims=1)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 11
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Standardize our dataset."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "(train, train_orig) = standardize(train)\n",
    "(test, test_orig) = standardize(test)\n",
    "(train_label, train_l_orig) = standardize(train_label)\n",
    "(test_label, test_l_orig) = standardize(test_label);"
   ],
   "metadata": {},
   "execution_count": 12
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Design matrix"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "247×2 Array{Float64,2}:\n 1.0   0.411044\n 1.0  -1.29419 \n 1.0  -1.98907 \n 1.0   1.19545 \n 1.0  -0.573727\n 1.0   2.69179 \n 1.0  -1.02988 \n 1.0   1.56207 \n 1.0   1.41287 \n 1.0   0.722248\n ⋮             \n 1.0  -1.38371 \n 1.0  -0.130367\n 1.0  -1.05545 \n 1.0  -0.147419\n 1.0  -0.160208\n 1.0  -0.641936\n 1.0   1.06329 \n 1.0   1.34892 \n 1.0   1.11871 "
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "cell_type": "code",
   "source": [
    "dmat = [ones(size(train, 1)) train]"
   ],
   "metadata": {},
   "execution_count": 13
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Bayesian linear regression."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "lrmodel = \"\n",
    "data {\n",
    "  int N; //the number of observations\n",
    "  int K; //the number of columns in the model matrix\n",
    "  real y[N]; //the response\n",
    "  matrix[N,K] X; //the model matrix\n",
    "}\n",
    "parameters {\n",
    "  vector[K] beta; //the regression parameters\n",
    "  real sigma; //the standard deviation\n",
    "}\n",
    "transformed parameters {\n",
    "  vector[N] linpred;\n",
    "  linpred <- X*beta;\n",
    "}\n",
    "model {\n",
    "  beta[1] ~ cauchy(0,10); // prior for the intercept following Gelman 2008\n",
    "\n",
    "  for(i in 2:K)\n",
    "   beta[i] ~ cauchy(0,2.5); // prior for the slopes following Gelman 2008\n",
    "\n",
    "  y ~ normal(linpred,sigma);\n",
    "}\n",
    "\";"
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Define the Stanmodel and set the output format to :mcmcchains."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File /Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan will be updated.\n",
      "\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "stanmodel = Stanmodel(name=\"linear_regression\",\n",
    "  model=lrmodel, output_format=:mcmcchains);"
   ],
   "metadata": {},
   "execution_count": 15
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Input data for cmdstan"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "lrdata = Dict(\"N\" => size(train, 1), \"K\" => size(dmat, 2), \"y\" => train_label, \"X\" => dmat);"
   ],
   "metadata": {},
   "execution_count": 16
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Sample using cmdstan"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -4.8288, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -5.64478, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -0.411041, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -86.2366, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -0.225509, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -2.69522, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -0.315977, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -0.253096, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -5.40098, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -0.702111, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -4.11972, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -3.17276, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n",
      "Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "Exception: normal_lpdf: Scale parameter is -0.643001, but must be > 0!  (in '/Users/rob/.julia/dev/StatisticalRethinking/scripts/00/tmp/linear_regression.stan' at line 21)\n",
      "\n",
      "If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "rc, chain, cnames = stan(stanmodel, lrdata, ProjDir, diagnostics=false,\n",
    "  summary=false, CmdStanDir=CMDSTAN_HOME);"
   ],
   "metadata": {},
   "execution_count": 17
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Convert to a  Chain object"
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Object of type Chains, with data of type 1000×257×4 Array{Float64,3}\n\nIterations        = 1001:2000\nThinning interval = 1\nChains            = 1, 2, 3, 4\nSamples per chain = 1000\nlinpred           = linpred.1, linpred.2, linpred.3, linpred.4, linpred.5, linpred.6, linpred.7, linpred.8, linpred.9, linpred.10, linpred.11, linpred.12, linpred.13, linpred.14, linpred.15, linpred.16, linpred.17, linpred.18, linpred.19, linpred.20, linpred.21, linpred.22, linpred.23, linpred.24, linpred.25, linpred.26, linpred.27, linpred.28, linpred.29, linpred.30, linpred.31, linpred.32, linpred.33, linpred.34, linpred.35, linpred.36, linpred.37, linpred.38, linpred.39, linpred.40, linpred.41, linpred.42, linpred.43, linpred.44, linpred.45, linpred.46, linpred.47, linpred.48, linpred.49, linpred.50, linpred.51, linpred.52, linpred.53, linpred.54, linpred.55, linpred.56, linpred.57, linpred.58, linpred.59, linpred.60, linpred.61, linpred.62, linpred.63, linpred.64, linpred.65, linpred.66, linpred.67, linpred.68, linpred.69, linpred.70, linpred.71, linpred.72, linpred.73, linpred.74, linpred.75, linpred.76, linpred.77, linpred.78, linpred.79, linpred.80, linpred.81, linpred.82, linpred.83, linpred.84, linpred.85, linpred.86, linpred.87, linpred.88, linpred.89, linpred.90, linpred.91, linpred.92, linpred.93, linpred.94, linpred.95, linpred.96, linpred.97, linpred.98, linpred.99, linpred.100, linpred.101, linpred.102, linpred.103, linpred.104, linpred.105, linpred.106, linpred.107, linpred.108, linpred.109, linpred.110, linpred.111, linpred.112, linpred.113, linpred.114, linpred.115, linpred.116, linpred.117, linpred.118, linpred.119, linpred.120, linpred.121, linpred.122, linpred.123, linpred.124, linpred.125, linpred.126, linpred.127, linpred.128, linpred.129, linpred.130, linpred.131, linpred.132, linpred.133, linpred.134, linpred.135, linpred.136, linpred.137, linpred.138, linpred.139, linpred.140, linpred.141, linpred.142, linpred.143, linpred.144, linpred.145, linpred.146, linpred.147, linpred.148, linpred.149, linpred.150, linpred.151, linpred.152, linpred.153, linpred.154, linpred.155, linpred.156, linpred.157, linpred.158, linpred.159, linpred.160, linpred.161, linpred.162, linpred.163, linpred.164, linpred.165, linpred.166, linpred.167, linpred.168, linpred.169, linpred.170, linpred.171, linpred.172, linpred.173, linpred.174, linpred.175, linpred.176, linpred.177, linpred.178, linpred.179, linpred.180, linpred.181, linpred.182, linpred.183, linpred.184, linpred.185, linpred.186, linpred.187, linpred.188, linpred.189, linpred.190, linpred.191, linpred.192, linpred.193, linpred.194, linpred.195, linpred.196, linpred.197, linpred.198, linpred.199, linpred.200, linpred.201, linpred.202, linpred.203, linpred.204, linpred.205, linpred.206, linpred.207, linpred.208, linpred.209, linpred.210, linpred.211, linpred.212, linpred.213, linpred.214, linpred.215, linpred.216, linpred.217, linpred.218, linpred.219, linpred.220, linpred.221, linpred.222, linpred.223, linpred.224, linpred.225, linpred.226, linpred.227, linpred.228, linpred.229, linpred.230, linpred.231, linpred.232, linpred.233, linpred.234, linpred.235, linpred.236, linpred.237, linpred.238, linpred.239, linpred.240, linpred.241, linpred.242, linpred.243, linpred.244, linpred.245, linpred.246, linpred.247\ninternals         = lp__, accept_stat__, stepsize__, treedepth__, n_leapfrog__, divergent__, energy__\nparameters        = beta.1, beta.2, sigma\n\n2-element Array{ChainDataFrame,1}\n\nSummary Statistics\n. Omitted printing of 2 columns\n│ Row │ parameters │ mean         │ std       │ naive_se    │ mcse        │\n│     │ \u001b[90mSymbol\u001b[39m     │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m     │\n├─────┼────────────┼──────────────┼───────────┼─────────────┼─────────────┤\n│ 1   │ beta.1     │ -0.000722466 │ 0.041992  │ 0.000663951 │ 0.000593477 │\n│ 2   │ beta.2     │ 0.754751     │ 0.0428155 │ 0.000676972 │ 0.000611258 │\n│ 3   │ sigma      │ 0.661892     │ 0.0305509 │ 0.000483053 │ 0.000438119 │\n\nQuantiles\n. Omitted printing of 1 columns\n│ Row │ parameters │ 2.5%       │ 25.0%      │ 50.0%       │ 75.0%     │\n│     │ \u001b[90mSymbol\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │\n├─────┼────────────┼────────────┼────────────┼─────────────┼───────────┤\n│ 1   │ beta.1     │ -0.0851149 │ -0.0277948 │ -0.00136394 │ 0.0268798 │\n│ 2   │ beta.2     │ 0.673216   │ 0.725782   │ 0.75351     │ 0.783635  │\n│ 3   │ sigma      │ 0.604295   │ 0.641031   │ 0.661437    │ 0.681913  │\n"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "cell_type": "code",
   "source": [
    "chns = set_section(chain, Dict(\n",
    "    :parameters => [\"beta.1\", \"beta.2\", \"sigma\"],\n",
    "    :linpred => [\"linpred.$i\" for i in 1:247],\n",
    "    :internals => [\"lp__\", \"accept_stat__\", \"stepsize__\", \"treedepth__\",\n",
    "      \"n_leapfrog__\", \"divergent__\", \"energy__\"]\n",
    "  )\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 18
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Describe the chains."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2-element Array{ChainDataFrame,1}\n\nSummary Statistics\n. Omitted printing of 2 columns\n│ Row │ parameters │ mean         │ std       │ naive_se    │ mcse        │\n│     │ \u001b[90mSymbol\u001b[39m     │ \u001b[90mFloat64\u001b[39m      │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m     │\n├─────┼────────────┼──────────────┼───────────┼─────────────┼─────────────┤\n│ 1   │ beta.1     │ -0.000722466 │ 0.041992  │ 0.000663951 │ 0.000593477 │\n│ 2   │ beta.2     │ 0.754751     │ 0.0428155 │ 0.000676972 │ 0.000611258 │\n│ 3   │ sigma      │ 0.661892     │ 0.0305509 │ 0.000483053 │ 0.000438119 │\n\nQuantiles\n. Omitted printing of 1 columns\n│ Row │ parameters │ 2.5%       │ 25.0%      │ 50.0%       │ 75.0%     │\n│     │ \u001b[90mSymbol\u001b[39m     │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m    │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m   │\n├─────┼────────────┼────────────┼────────────┼─────────────┼───────────┤\n│ 1   │ beta.1     │ -0.0851149 │ -0.0277948 │ -0.00136394 │ 0.0268798 │\n│ 2   │ beta.2     │ 0.673216   │ 0.725782   │ 0.75351     │ 0.783635  │\n│ 3   │ sigma      │ 0.604295   │ 0.641031   │ 0.661437    │ 0.681913  │\n"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "cell_type": "code",
   "source": [
    "MCMCChains.describe(chns)"
   ],
   "metadata": {},
   "execution_count": 19
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Perform multivariate OLS."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = (::getfield(StatsModels, Symbol(\"##18#19\")){DataFrame})(::Symbol) at modelframe.jl:145\n",
      "└ @ StatsModels /Users/rob/.julia/packages/StatsModels/pBxdt/src/modelframe.jl:145\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = check_non_redundancy!(::StatsModels.Terms, ::DataFrame) at modelframe.jl:84\n",
      "└ @ StatsModels /Users/rob/.julia/packages/StatsModels/pBxdt/src/modelframe.jl:84\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = #modelmat_cols#30(::Bool, ::typeof(StatsModels.modelmat_cols), ::Type{Array{Float64,2}}, ::Symbol, ::StatsModels.ModelFrame) at modelmatrix.jl:34\n",
      "└ @ StatsModels /Users/rob/.julia/packages/StatsModels/pBxdt/src/modelmatrix.jl:34\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = model_response(::StatsModels.ModelFrame) at modelframe.jl:181\n",
      "└ @ StatsModels /Users/rob/.julia/packages/StatsModels/pBxdt/src/modelframe.jl:181\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "StatsModels.DataFrameRegressionModel{GLM.LinearModel{GLM.LmResp{Array{Float64,1}},GLM.DensePredChol{Float64,LinearAlgebra.Cholesky{Float64,Array{Float64,2}}}},Array{Float64,2}}\n\nFormula: height ~ 1 + weight\n\nCoefficients:\n─────────────────────────────────────────────────────\n               Estimate  Std.Error  t value  Pr(>|t|)\n─────────────────────────────────────────────────────\n(Intercept)  115.386     2.20778    52.2634    <1e-99\nweight         0.870105  0.0484398  17.9626    <1e-45\n─────────────────────────────────────────────────────"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "cell_type": "code",
   "source": [
    "ols = lm(@formula(height ~ weight), train_cut)"
   ],
   "metadata": {},
   "execution_count": 20
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Store our predictions in the original dataframe."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = (::getfield(StatsModels, Symbol(\"##18#19\")){DataFrame})(::Symbol) at modelframe.jl:145\n",
      "└ @ StatsModels /Users/rob/.julia/packages/StatsModels/pBxdt/src/modelframe.jl:145\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = check_non_redundancy!(::StatsModels.Terms, ::DataFrame) at modelframe.jl:84\n",
      "└ @ StatsModels /Users/rob/.julia/packages/StatsModels/pBxdt/src/modelframe.jl:84\n",
      "┌ Warning: `getindex(df::DataFrame, col_ind::ColumnIndex)` is deprecated, use `df[!, col_ind]` instead.\n",
      "│   caller = #modelmat_cols#30(::Bool, ::typeof(StatsModels.modelmat_cols), ::Type{Array{Float64,2}}, ::Symbol, ::StatsModels.ModelFrame) at modelmatrix.jl:34\n",
      "└ @ StatsModels /Users/rob/.julia/packages/StatsModels/pBxdt/src/modelmatrix.jl:34\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "train_cut.OLSPrediction = predict(ols);\n",
    "test_cut.OLSPrediction = predict(ols, test_cut);"
   ],
   "metadata": {},
   "execution_count": 21
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Make a prediction given an input vector."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "prediction (generic function with 1 method)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "cell_type": "code",
   "source": [
    "function prediction(chn, x)\n",
    "    α = Array(chn[Symbol(\"beta.1\")]);\n",
    "    β = Array(chn[Symbol(\"beta.2\")]);\n",
    "    return  mean(α) .+ x .* mean(β)\n",
    "end"
   ],
   "metadata": {},
   "execution_count": 22
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Calculate the predictions for the training and testing sets."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "train_cut.BayesPredictions = unstandardize(prediction(chns, train), train_l_orig)[:,1];\n",
    "test_cut.BayesPredictions = unstandardize(prediction(chns, test), test_l_orig)[:,1];"
   ],
   "metadata": {},
   "execution_count": 23
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Show the first side rows of the modified dataframe."
   ],
   "metadata": {}
  },
  {
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌ Warning: `getindex(df::DataFrame, col_inds::Union{AbstractVector, Regex, Not})` is deprecated, use `df[:, col_inds]` instead.\n",
      "│   caller = top-level scope at string:2\n",
      "└ @ Core string:2\n",
      "\n",
      "Training set:\n",
      "  Bayes loss: 6253.907049030092\n",
      "  OLS loss: 6253.889517499792\n",
      "Test set:\n",
      "  Bayes loss: 2744.4872150742913\n",
      "  OLS loss: 2820.197967367609\n"
     ]
    }
   ],
   "cell_type": "code",
   "source": [
    "remove_names = filter(x->!in(x, [:age, :male]), names(test_cut));\n",
    "test_cut = test_cut[remove_names];\n",
    "first(test_cut, 6)\n",
    "\n",
    "bayes_loss1 = sum((train_cut.BayesPredictions - train_cut.height).^2);\n",
    "ols_loss1 = sum((train_cut.OLSPrediction - train_cut.height).^2);\n",
    "\n",
    "bayes_loss2 = sum((test_cut.BayesPredictions - test_cut.height).^2);\n",
    "ols_loss2 = sum((test_cut.OLSPrediction - test_cut.height).^2);\n",
    "\n",
    "println(\"\\nTraining set:\")\n",
    "println(\"  Bayes loss: $bayes_loss1\")\n",
    "println(\"  OLS loss: $ols_loss1\")\n",
    "\n",
    "println(\"Test set:\")\n",
    "println(\"  Bayes loss: $bayes_loss2\")\n",
    "println(\"  OLS loss: $ols_loss2\")"
   ],
   "metadata": {},
   "execution_count": 24
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Plot the chains."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "#plot(chain)"
   ],
   "metadata": {},
   "execution_count": 25
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0-alpha.26"
  },
  "kernelspec": {
   "name": "julia-1.3",
   "display_name": "Julia 1.3.0-alpha.26",
   "language": "julia"
  }
 },
 "nbformat": 4
}
